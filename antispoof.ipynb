{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 3842332,
          "sourceType": "datasetVersion",
          "datasetId": 2286778
        }
      ],
      "dockerImageVersionId": 31090,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Для начала зададим все необходимые константы (ключ для wandb, название проекта, путь к файлам, гиперпараметры и так далее)"
      ],
      "metadata": {
        "id": "54tXVtt0EWH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KEY = \"\"\n",
        "PROJECT_NAME = \"antispoof\"\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 20\n",
        "LEARNING_RATE = 3e-4\n",
        "MAX_LR = 1e-3\n",
        "SEED = 31\n",
        "SAMPLE_RATE = 16000\n",
        "N_FFT = 512\n",
        "WIN_LENGTH = 400\n",
        "HOP_LENGTH = 160\n",
        "MAX_FRAMES = 200\n",
        "NUM_WORKERS = 2\n",
        "PIN_MEMORY = True\n",
        "\n",
        "TRAIN_AUDIO_DIR = \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac\"\n",
        "DEV_AUDIO_DIR = \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_dev/flac\"\n",
        "EVAL_AUDIO_DIR = \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_eval/flac\"\n",
        "TRAIN_PROTOCOL = \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\"\n",
        "DEV_PROTOCOL = \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\"\n",
        "EVAL_PROTOCOL = \"/kaggle/input/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\"\n",
        "CACHE_DIR = \"/tmp/spec_cache\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:19.706673Z",
          "iopub.execute_input": "2025-08-08T17:22:19.706898Z",
          "iopub.status.idle": "2025-08-08T17:22:19.714253Z",
          "shell.execute_reply.started": "2025-08-08T17:22:19.706880Z",
          "shell.execute_reply": "2025-08-08T17:22:19.713553Z"
        },
        "id": "s_QRzwLKEWH4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем необходимые библиотеки"
      ],
      "metadata": {
        "id": "TfsMnpBFEWH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchaudio import transforms as T\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import hashlib"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:19.715443Z",
          "iopub.execute_input": "2025-08-08T17:22:19.715636Z",
          "iopub.status.idle": "2025-08-08T17:22:28.880158Z",
          "shell.execute_reply.started": "2025-08-08T17:22:19.715620Z",
          "shell.execute_reply": "2025-08-08T17:22:28.879313Z"
        },
        "id": "PYALRSsXEWH6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подключимся к системе wandb и зададим исходные параметры. Установим сид, чтобы можно было тестировать различные гипотези без страха потерять текущие изменения"
      ],
      "metadata": {
        "id": "-jgwxu2-EWH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=KEY)\n",
        "\n",
        "wandb.init(project=PROJECT_NAME, config={\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"num_epochs\": NUM_EPOCHS,\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"max_lr\": MAX_LR,\n",
        "    \"seed\": SEED,\n",
        "    \"sample_rate\": SAMPLE_RATE\n",
        "})\n",
        "\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_random_seed(SEED)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:28.880899Z",
          "iopub.execute_input": "2025-08-08T17:22:28.881442Z",
          "iopub.status.idle": "2025-08-08T17:22:41.935685Z",
          "shell.execute_reply.started": "2025-08-08T17:22:28.881410Z",
          "shell.execute_reply": "2025-08-08T17:22:41.935128Z"
        },
        "id": "ALXEsk1aEWH7",
        "outputId": "15fcfd17-8406-4420-ec7b-1b18faddbe32"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfamaxth\u001b[0m (\u001b[33mfamaxth-hse-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.20.1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250808_172234-dcf58use</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/famaxth-hse-university/antispoof/runs/dcf58use' target=\"_blank\">comfy-dew-5</a></strong> to <a href='https://wandb.ai/famaxth-hse-university/antispoof' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/famaxth-hse-university/antispoof' target=\"_blank\">https://wandb.ai/famaxth-hse-university/antispoof</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/famaxth-hse-university/antispoof/runs/dcf58use' target=\"_blank\">https://wandb.ai/famaxth-hse-university/antispoof/runs/dcf58use</a>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем основную архитектуру сети (LightCNN + MFM)"
      ],
      "metadata": {
        "id": "QjMAC4xBEWH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MFM(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x1, x2 = torch.chunk(x, 2, dim=1)\n",
        "        return torch.max(x1, x2)\n",
        "\n",
        "class LightCNN(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=2, freq_bins=None, time_frames=MAX_FRAMES):\n",
        "        super().__init__()\n",
        "\n",
        "        if freq_bins is None: freq_bins = N_FFT // 2 + 1\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2), nn.BatchNorm2d(64), MFM(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 96, kernel_size=1), nn.BatchNorm2d(96), MFM(),\n",
        "            nn.Conv2d(48, 96, kernel_size=3, padding=1), nn.BatchNorm2d(96), MFM(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(48, 128, kernel_size=1), nn.BatchNorm2d(128), MFM(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), MFM(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 256, kernel_size=1), nn.BatchNorm2d(256), MFM(),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), MFM(), nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 1, freq_bins, time_frames)\n",
        "            out = self.net(dummy)\n",
        "            flatten_size = out.shape[1] * out.shape[2] * out.shape[3]\n",
        "\n",
        "        self.fc1 = nn.Linear(flatten_size, 256)\n",
        "        self.mfm_fc = MFM()\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.net(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.mfm_fc(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:41.936439Z",
          "iopub.execute_input": "2025-08-08T17:22:41.937018Z",
          "iopub.status.idle": "2025-08-08T17:22:41.946207Z",
          "shell.execute_reply.started": "2025-08-08T17:22:41.936996Z",
          "shell.execute_reply": "2025-08-08T17:22:41.945607Z"
        },
        "id": "_x8trnGEEWH9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это кусок кода, который отвечает за подготовку и аугментацию звуковых данных перед подачей в нейросеть\n"
      ],
      "metadata": {
        "id": "86jt8FQlEWH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cmvn(tensor, eps=1e-6):\n",
        "    # Эта функция нужна для нормализации спектрограммы\n",
        "    mean = tensor.mean(dim=1, keepdim=True)\n",
        "    std = tensor.std(dim=1, keepdim=True) + eps\n",
        "    return (tensor - mean) / std\n",
        "\n",
        "def get_log_spec(tmp, sample_rate, n_fft=N_FFT, win_length=WIN_LENGTH, hop_length=HOP_LENGTH):\n",
        "    # Логарифм спектрограммы\n",
        "    if tmp.dim() == 1:\n",
        "        tmp = tmp.unsqueeze(0)\n",
        "\n",
        "    window = torch.hann_window(win_length).to(tmp.device)\n",
        "    stft = torch.stft(tmp, n_fft=n_fft, win_length=win_length, hop_length=hop_length, window=window, return_complex=True)\n",
        "\n",
        "    spec = stft.abs().squeeze(0)\n",
        "    spec = spec + 1e-6\n",
        "\n",
        "    log_spec = torch.log(spec)\n",
        "    log_spec = cmvn(log_spec)\n",
        "\n",
        "    return log_spec\n",
        "\n",
        "def get_cache_path(cache_dir, audio_path, n_fft, win_length, hop_length, max_frames):\n",
        "    # Формирует уникальный путь для кэширования спектрограмм\n",
        "    key = f\"{audio_path}|{n_fft}|{win_length}|{hop_length}|{max_frames}\"\n",
        "    h = hashlib.md5(key.encode()).hexdigest()\n",
        "    return os.path.join(cache_dir, f\"{h}.pt\")\n",
        "\n",
        "class AudioAugment():\n",
        "    # Аугментация\n",
        "\n",
        "    def __init__(self, sample_rate=SAMPLE_RATE):\n",
        "\n",
        "        self.sample_rate = sample_rate\n",
        "        self.time_mask = T.TimeMasking(time_mask_param=35)\n",
        "        self.freq_mask = T.FrequencyMasking(freq_mask_param=15)\n",
        "\n",
        "    def __call__(self, tmp):\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            gain_db = random.uniform(-3.0, 3.0)\n",
        "            tmp = T.Vol(gain=gain_db, gain_type='db')(tmp)\n",
        "\n",
        "        if random.random() < 0.5:\n",
        "            noise = torch.randn_like(tmp) * 0.0035\n",
        "            tmp = tmp + noise\n",
        "\n",
        "        return tmp"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:41.948076Z",
          "iopub.execute_input": "2025-08-08T17:22:41.948285Z",
          "iopub.status.idle": "2025-08-08T17:22:41.998126Z",
          "shell.execute_reply.started": "2025-08-08T17:22:41.948268Z",
          "shell.execute_reply": "2025-08-08T17:22:41.997437Z"
        },
        "id": "ikOGyHq8EWH-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь напишем Dataset для преобразования данных в удобный для нас формат"
      ],
      "metadata": {
        "id": "pHo25KWqEWH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, file_list, labels, root_dir, augment=False, cache_dir=CACHE_DIR, n_fft=N_FFT, win_length=WIN_LENGTH, hop_length=HOP_LENGTH, max_frames=MAX_FRAMES):\n",
        "        self.file_list = file_list\n",
        "        self.labels = labels\n",
        "        self.root_dir = root_dir\n",
        "        self.augment = augment\n",
        "        self.augmenter = AudioAugment() if augment else None\n",
        "        self.cache_dir = cache_dir\n",
        "        self.n_fft = n_fft\n",
        "        self.win_length = win_length\n",
        "        self.hop_length = hop_length\n",
        "        self.max_frames = max_frames\n",
        "        self.time_mask = T.TimeMasking(time_mask_param=35)\n",
        "        self.freq_mask = T.FrequencyMasking(freq_mask_param=15)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.file_list[idx]\n",
        "        label = self.labels[idx]\n",
        "        path = os.path.join(self.root_dir, filename)\n",
        "\n",
        "        cache_path = get_cache_path(self.cache_dir, path, self.n_fft, self.win_length, self.hop_length, self.max_frames)\n",
        "\n",
        "        if os.path.exists(cache_path) and not self.augment:\n",
        "            spec = torch.load(cache_path)\n",
        "        else:\n",
        "            tmp, sr = torchaudio.load(path)\n",
        "            if tmp.dim() > 1:\n",
        "                tmp = tmp.mean(dim=0, keepdim=True)\n",
        "            if self.augment and self.augmenter is not None:\n",
        "                tmp = self.augmenter(tmp)\n",
        "            spec = get_log_spec(tmp.squeeze(0), sr, n_fft=self.n_fft, win_length=self.win_length, hop_length=self.hop_length)\n",
        "            if self.augment:\n",
        "                spec = self.freq_mask(spec)\n",
        "                spec = self.time_mask(spec)\n",
        "            if spec.size(1) < self.max_frames:\n",
        "                spec = F.pad(spec, (0, self.max_frames - spec.size(1)))\n",
        "            else:\n",
        "                spec = spec[:, :self.max_frames]\n",
        "            if not self.augment:\n",
        "                try:\n",
        "                    torch.save(spec, cache_path)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        spec = spec.unsqueeze(0)\n",
        "\n",
        "        return spec.float(), label"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:41.998796Z",
          "iopub.execute_input": "2025-08-08T17:22:41.999044Z",
          "iopub.status.idle": "2025-08-08T17:22:42.013986Z",
          "shell.execute_reply.started": "2025-08-08T17:22:41.999026Z",
          "shell.execute_reply": "2025-08-08T17:22:42.013471Z"
        },
        "id": "3UcHZHU9EWH-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функции для подсчета EER"
      ],
      "metadata": {
        "id": "k18YmjUWEWH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_det_curve(target_scores, nontarget_scores):\n",
        "    n_scores = target_scores.size + nontarget_scores.size\n",
        "    all_scores = np.concatenate((target_scores, nontarget_scores))\n",
        "    labels = np.concatenate(\n",
        "        (np.ones(target_scores.size), np.zeros(nontarget_scores.size)))\n",
        "    indices = np.argsort(all_scores, kind='mergesort')\n",
        "    labels = labels[indices]\n",
        "    tar_trial_sums = np.cumsum(labels)\n",
        "    nontarget_trial_sums = nontarget_scores.size - \\\n",
        "        (np.arange(1, n_scores + 1) - tar_trial_sums)\n",
        "    frr = np.concatenate(\n",
        "        (np.atleast_1d(0), tar_trial_sums / target_scores.size))\n",
        "    far = np.concatenate((np.atleast_1d(1), nontarget_trial_sums /\n",
        "                          nontarget_scores.size))\n",
        "    thresholds = np.concatenate(\n",
        "        (np.atleast_1d(all_scores[indices[0]] - 0.001), all_scores[indices]))\n",
        "    return frr, far, thresholds\n",
        "\n",
        "def compute_eer(bonafide_scores, other_scores):\n",
        "    frr, far, thresholds = compute_det_curve(bonafide_scores, other_scores)\n",
        "    abs_diffs = np.abs(frr - far)\n",
        "    min_index = np.argmin(abs_diffs)\n",
        "    eer = np.mean((frr[min_index], far[min_index]))\n",
        "    return eer, thresholds[min_index]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:42.014728Z",
          "iopub.execute_input": "2025-08-08T17:22:42.015406Z",
          "iopub.status.idle": "2025-08-08T17:22:42.030560Z",
          "shell.execute_reply.started": "2025-08-08T17:22:42.015368Z",
          "shell.execute_reply": "2025-08-08T17:22:42.030001Z"
        },
        "id": "wl_wnIfwEWH_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь необходимо задать программу, которая будет подсчитывать итоговый EER для модели (на данных eval)"
      ],
      "metadata": {
        "id": "_DRMHRpNEWH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_protocol_file(path):\n",
        "    files = []\n",
        "    labels = []\n",
        "\n",
        "    with open(path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            files.append(parts[1] + '.flac')\n",
        "            if parts[-1] == 'bonafide':\n",
        "                labels.append(1)\n",
        "            else:\n",
        "                labels.append(0)\n",
        "\n",
        "    return files, labels\n",
        "\n",
        "def evaluate():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    freq_bins = N_FFT // 2 + 1\n",
        "    model = LightCNN(num_classes=2, freq_bins=freq_bins, time_frames=MAX_FRAMES).to(device)\n",
        "    model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    eval_files, eval_labels = load_protocol_file(EVAL_PROTOCOL)\n",
        "    spoof_scores, bona_scores = [], []\n",
        "\n",
        "    for filename, label in tqdm(zip(eval_files, eval_labels), desc=\"Evaluating (eval set)\", total=len(eval_files)):\n",
        "        tmp, sr = torchaudio.load(os.path.join(EVAL_AUDIO_DIR, filename))\n",
        "\n",
        "        if tmp.dim() > 1:\n",
        "            tmp = tmp.mean(dim=0, keepdim=True)\n",
        "\n",
        "        spec = get_log_spec(tmp.squeeze(0), sr).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        if spec.size(3) < MAX_FRAMES:\n",
        "            spec = F.pad(spec, (0, MAX_FRAMES - spec.size(3)))\n",
        "        else:\n",
        "            spec = spec[:, :, :, :MAX_FRAMES]\n",
        "\n",
        "        spec = spec.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prob = torch.softmax(model(spec), dim=1)[0, 1].item()\n",
        "\n",
        "        if label == 1:\n",
        "            bona_scores.append(prob)\n",
        "        else:\n",
        "            spoof_scores.append(prob)\n",
        "\n",
        "    eer, thr = compute_eer(np.array(bona_scores), np.array(spoof_scores))\n",
        "    print(f\"✅ FINAL EER on EVAL: {eer*100:.4f}% (thr={thr:.5f})\")\n",
        "    wandb.log({\"final_eval_eer\": eer})\n",
        "    return eer, thr"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:42.031197Z",
          "iopub.execute_input": "2025-08-08T17:22:42.031397Z",
          "iopub.status.idle": "2025-08-08T17:22:42.041948Z",
          "shell.execute_reply.started": "2025-08-08T17:22:42.031367Z",
          "shell.execute_reply": "2025-08-08T17:22:42.041272Z"
        },
        "id": "61t1w8-dEWIA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для обучения"
      ],
      "metadata": {
        "id": "auQQEKxCEWIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device:\", device)\n",
        "\n",
        "    train_files, train_labels = load_protocol_file(TRAIN_PROTOCOL)\n",
        "    dev_files, dev_labels = load_protocol_file(DEV_PROTOCOL)\n",
        "\n",
        "    train_set = AudioDataSet(train_files, train_labels, TRAIN_AUDIO_DIR, augment=True, cache_dir=CACHE_DIR)\n",
        "    dev_set = AudioDataSet(dev_files, dev_labels, DEV_AUDIO_DIR, augment=False, cache_dir=CACHE_DIR)\n",
        "\n",
        "    train_loader = DataLoader(train_set, BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "    dev_loader = DataLoader(dev_set, BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "\n",
        "    freq_bins = N_FFT // 2 + 1\n",
        "    model = LightCNN(num_classes=2, freq_bins=freq_bins, time_frames=MAX_FRAMES).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
        "\n",
        "    steps_per_epoch = max(1, len(train_loader))\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=MAX_LR, steps_per_epoch=steps_per_epoch, epochs=NUM_EPOCHS)\n",
        "\n",
        "    best_eer = float(\"inf\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch} [Train]\")\n",
        "        for x, y in pbar:\n",
        "            x = x.to(device, non_blocking=PIN_MEMORY)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix(loss=total_loss/(pbar.n+1), lr=optimizer.param_groups[0]['lr'])\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        wandb.log({\"train_loss\": avg_train_loss, \"epoch\": epoch, \"lr\": optimizer.param_groups[0]['lr']})\n",
        "        model.eval()\n",
        "        spoof_scores, bona_scores = [], []\n",
        "        all_labels, all_preds = [], []\n",
        "        with torch.no_grad():\n",
        "            for x, y in tqdm(dev_loader, desc=f\"Epoch {epoch} [Eval]\"):\n",
        "                x = x.to(device, non_blocking=PIN_MEMORY)\n",
        "                outputs = model(x)\n",
        "                probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
        "                preds = outputs.argmax(dim=1).cpu().numpy()\n",
        "                for score, label in zip(probs, y.numpy()):\n",
        "                    (bona_scores if label == 1 else spoof_scores).append(score)\n",
        "                all_labels.extend(y.numpy())\n",
        "                all_preds.extend(preds)\n",
        "\n",
        "        eer, thr = compute_eer(np.array(bona_scores), np.array(spoof_scores))\n",
        "        print(f\"Epoch {epoch}: DEV EER = {eer*100:.4f}%, thr={thr:.5f}\")\n",
        "        wandb.log({\"dev_eer\": eer, \"epoch\": epoch})\n",
        "\n",
        "        cm = confusion_matrix(all_labels, all_preds, normalize='true')\n",
        "        disp = ConfusionMatrixDisplay(cm, display_labels=[\"spoof\", \"bona\"])\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "        plt.title(f\"Confusion Matrix (Epoch {epoch})\")\n",
        "        plt.savefig(f\"conf_matrix_epoch_{epoch}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        if eer < best_eer:\n",
        "            best_eer = eer\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(f\"New best DEV EER: {best_eer*100:.4f}%. Model saved.\")\n",
        "            wandb.log({\"best_dev_eer\": best_eer})\n",
        "\n",
        "    print(\"Training finished. Best DEV EER: %.4f%%\" % (best_eer * 100))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:42.042720Z",
          "iopub.execute_input": "2025-08-08T17:22:42.043159Z",
          "iopub.status.idle": "2025-08-08T17:22:42.057962Z",
          "shell.execute_reply.started": "2025-08-08T17:22:42.043143Z",
          "shell.execute_reply": "2025-08-08T17:22:42.057430Z"
        },
        "id": "AB85IrpXEWIA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для создания csv с посчитанным предсказаниями относительно входных данных"
      ],
      "metadata": {
        "id": "QMl-5PL_EWIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_csv(file_out=\"arantitov.csv\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    freq_bins = N_FFT // 2 + 1\n",
        "\n",
        "    model = LightCNN(num_classes=2, freq_bins=freq_bins, time_frames=MAX_FRAMES).to(device)\n",
        "    model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    eval_files = [f for f in os.listdir(EVAL_AUDIO_DIR) if f.endswith(\".flac\")]\n",
        "    predictions = []\n",
        "    for filename in tqdm(sorted(eval_files), desc=\"Predicting (eval folder)\"):\n",
        "        tmp, sr = torchaudio.load(os.path.join(EVAL_AUDIO_DIR, filename))\n",
        "        if tmp.dim() > 1:\n",
        "            tmp = tmp.mean(dim=0, keepdim=True)\n",
        "\n",
        "        spec = get_log_spec(tmp.squeeze(0), sr).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        if spec.size(3) < MAX_FRAMES:\n",
        "            spec = F.pad(spec, (0, MAX_FRAMES - spec.size(3)))\n",
        "        else:\n",
        "            spec = spec[:, :, :, :MAX_FRAMES]\n",
        "\n",
        "        spec = spec.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prob = torch.softmax(model(spec), dim=1)[0, 1].item()\n",
        "\n",
        "        predictions.append((filename.replace(\".flac\", \"\"), prob))\n",
        "\n",
        "    df = pd.DataFrame(predictions, columns=[\"utt_id\", \"score\"])\n",
        "    df.to_csv(file_out, index=False)\n",
        "    print(f\"Predictions saved to {file_out}\")\n",
        "\n",
        "    return file_out"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:42.058545Z",
          "iopub.execute_input": "2025-08-08T17:22:42.058781Z",
          "iopub.status.idle": "2025-08-08T17:22:42.071883Z",
          "shell.execute_reply.started": "2025-08-08T17:22:42.058765Z",
          "shell.execute_reply": "2025-08-08T17:22:42.071237Z"
        },
        "id": "7500iIgAEWIA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустим и обучим модель"
      ],
      "metadata": {
        "id": "vVARUjmtEWIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train()\n",
        "evaluate()\n",
        "make_csv()\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-08T17:22:42.073038Z",
          "iopub.execute_input": "2025-08-08T17:22:42.073279Z",
          "iopub.status.idle": "2025-08-08T18:34:56.189457Z",
          "shell.execute_reply.started": "2025-08-08T17:22:42.073261Z",
          "shell.execute_reply": "2025-08-08T18:34:56.188597Z"
        },
        "id": "I0vcARx6EWIB",
        "outputId": "d91ebc9e-fe16-4bd2-e9fd-01f9cb0fd9f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Device: cuda\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 0 [Train]: 100%|██████████| 794/794 [02:33<00:00,  5.19it/s, loss=0.536, lr=0.000152]\nEpoch 0 [Eval]: 100%|██████████| 777/777 [02:37<00:00,  4.93it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 0: DEV EER = 1.6450%, thr=0.01690\nNew best DEV EER: 1.6450%. Model saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 1 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.21it/s, loss=0.295, lr=0.000437]\nEpoch 1 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.27it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1: DEV EER = 0.7075%, thr=0.43233\nNew best DEV EER: 0.7075%. Model saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.22it/s, loss=0.194, lr=0.00076] \nEpoch 2 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.20it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2: DEV EER = 0.3936%, thr=0.12950\nNew best DEV EER: 0.3936%. Model saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.22it/s, loss=0.186, lr=0.000971]\nEpoch 3 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.17it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3: DEV EER = 0.7782%, thr=0.24767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.22it/s, loss=0.168, lr=0.000994]\nEpoch 4 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.20it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4: DEV EER = 0.2809%, thr=0.14520\nNew best DEV EER: 0.2809%. Model saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5 [Train]: 100%|██████████| 794/794 [02:31<00:00,  5.23it/s, loss=0.154, lr=0.00095] \nEpoch 5 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.26it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5: DEV EER = 0.3936%, thr=0.10192\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 6 [Train]: 100%|██████████| 794/794 [02:31<00:00,  5.23it/s, loss=0.149, lr=0.000866]\nEpoch 6 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.26it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6: DEV EER = 0.1172%, thr=0.07743\nNew best DEV EER: 0.1172%. Model saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 7 [Train]: 100%|██████████| 794/794 [02:31<00:00,  5.23it/s, loss=0.14, lr=0.00075]  \nEpoch 7 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.26it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7: DEV EER = 0.0774%, thr=0.17835\nNew best DEV EER: 0.0774%. Model saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 8 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.22it/s, loss=0.137, lr=0.000611]\nEpoch 8 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.15it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8: DEV EER = 0.0796%, thr=0.17596\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 9 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.22it/s, loss=0.133, lr=0.000462]\nEpoch 9 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.24it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9: DEV EER = 0.0465%, thr=0.15808\nNew best DEV EER: 0.0465%. Model saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 10 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.21it/s, loss=0.129, lr=0.000317]\nEpoch 10 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.19it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10: DEV EER = 0.0045%, thr=0.21449\nNew best DEV EER: 0.0045%. Model saved.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 11 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.22it/s, loss=0.126, lr=0.000188]\nEpoch 11 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.25it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 11: DEV EER = 0.0398%, thr=0.10571\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 12 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.22it/s, loss=0.124, lr=8.68e-5] \nEpoch 12 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.21it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 12: DEV EER = 0.0398%, thr=0.13282\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 13 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.22it/s, loss=0.123, lr=2.22e-5]\nEpoch 13 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.20it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 13: DEV EER = 0.0398%, thr=0.09471\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 14 [Train]: 100%|██████████| 794/794 [02:32<00:00,  5.21it/s, loss=0.123, lr=4.04e-9]\nEpoch 14 [Eval]: 100%|██████████| 777/777 [00:36<00:00, 21.19it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 14: DEV EER = 0.0376%, thr=0.08144\nTraining finished. Best DEV EER: 0.0045%\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating (eval set): 100%|██████████| 71237/71237 [14:51<00:00, 79.95it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "✅ FINAL EER on EVAL: 5.6582% (thr=0.89429)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Predicting (eval folder): 100%|██████████| 71933/71933 [08:01<00:00, 149.43it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Predictions saved to arantitov.csv\nDone.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}
